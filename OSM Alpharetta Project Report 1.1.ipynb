{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project:  OpenStreetMap Data Wrangling with SQL\n",
    "\n",
    "## OSM Data of Alpharetta, Georgia\n",
    "\n",
    "### Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    ">This map is the area I lived for one year after the undergradute degree. This expericen may help me to understand the result of database quering. I am interested to see what we can find out. The original dataset is from [OpenStreetMap](https://www.openstreetmap.org/relation/119572), which can be downloaded in XML format with the [OverpassAPI](https://overpass-api.de/api/map?bbox=-84.3601,33.9841,-84.2006,34.1634) option on the export menu. Here, we apply the data wrangling skill learned from the course to process the dataset. In general, the raw data will be cleaned and converted in CSV format. Then, the cleaned data will be transfered into SQLite. By using the tools in SQLite, we can get some statistics overview of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All libraries used in this project\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import csv\n",
    "\n",
    "import cerberus\n",
    "import sqlite3\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Database schema module\n",
    "sys.path.append('Schema//')\n",
    "import schema_map_p1 as schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data Wrangling\n",
    "\n",
    ">In this section, the raw data will be downloaded, cleaned and converted in CSV format. Then, the cleaned data will be imported into a SQLite database, which will be used in the next section.\n",
    "\n",
    "### Steps\n",
    "<ul>\n",
    "<li><a href=\"#download\">Download the Dataset</a></li>\n",
    "<li><a href=\"#audit\">Audit the Dataset</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='download'></a>\n",
    "### Download the Dataset\n",
    "\n",
    ">Download the original dataset from the OpenStreetMap by using the Overpass API option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function used to download the original dataset\n",
    "#It takes Overpass API url provided by OpenStreetMap and the filename used to store the file.  \n",
    "def download_dataset(api_url, local_filename):\n",
    "    total_size = 85557150 \n",
    "    \n",
    "    if os.path.exists(local_filename):\n",
    "        if os.path.getsize(local_filename) == total_size:\n",
    "            print 'Found and verified', local_filename\n",
    "            return None\n",
    "\n",
    "    r = requests.get(api_url, stream=True)\n",
    "\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        print \"Downloading %s\" % local_filename, '...'\n",
    "        \n",
    "        dl_size = 0\n",
    "        for chunk in r.iter_content(chunk_size=4096):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                dl_size += len(chunk)\n",
    "                done = int(100 * dl_size / float(total_size))\n",
    "                sys.stdout.write(\"\\r[%s%s]\" % ('-' * done, ' ' * (100 - done)))    \n",
    "                sys.stdout.flush()\n",
    "        \n",
    "\n",
    "    print '\\nDownload finished. {} is ready.'.format(local_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://overpass-api.de/api/map?bbox=-84.3601,33.9920,-84.2004,34.1554'\n",
    "\n",
    "osm_filename = 'data/alpharetta.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified data/alpharetta.osm\n"
     ]
    }
   ],
   "source": [
    "download_dataset(url, osm_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='audit'></a>\n",
    "### Audit the Dataset\n",
    "\n",
    ">Download the original dataset from the OpenStreetMap by using the Overpass API option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t```XML\n",
    "\t<tag k=\"tiger:name_base\" v=\"Stonewall\"/> \n",
    "\t<tag k=\"tiger:name_direction_prefix\" v=\"W\"/> \n",
    "\t<tag k=\"tiger:name_type\" v=\"St\"/>\n",
    "\t```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element types and occurrence of alpharetta.osm:\n",
      "\n",
      "[('nd', 418468),\n",
      " ('node', 360143),\n",
      " ('tag', 204837),\n",
      " ('way', 40794),\n",
      " ('member', 4979),\n",
      " ('relation', 180),\n",
      " ('osm', 1),\n",
      " ('note', 1),\n",
      " ('meta', 1),\n",
      " ('bounds', 1)]\n",
      "\n",
      "--- 2.53500008583 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', )):\n",
    "        if elem.tag not in tags:\n",
    "            tags[elem.tag] = 1\n",
    "        else:\n",
    "            tags[elem.tag] += 1\n",
    "    return tags\n",
    "\n",
    "start_time = time.time()\n",
    "tags = count_tags(osm_filename)\n",
    "sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in tags.items()], reverse=True)]\n",
    "\n",
    "print 'Element types and occurrence of alpharetta.osm:\\n'\n",
    "pprint.pprint(sorted_by_occurrence)\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes and occurrence of alpharetta.osm:\n",
      "\n",
      "[('ref', 423447),\n",
      " ('version', 401118),\n",
      " ('user', 401117),\n",
      " ('uid', 401117),\n",
      " ('timestamp', 401117),\n",
      " ('id', 401117),\n",
      " ('changeset', 401117),\n",
      " ('lon', 360143),\n",
      " ('lat', 360143),\n",
      " ('v', 204837),\n",
      " ('k', 204837),\n",
      " ('type', 4979),\n",
      " ('role', 4979),\n",
      " ('osm_base', 1),\n",
      " ('minlon', 1),\n",
      " ('minlat', 1),\n",
      " ('maxlon', 1),\n",
      " ('maxlat', 1),\n",
      " ('generator', 1)]\n",
      "\n",
      "--- 3.28100013733 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# From case study\n",
    "def count_attrs(filename):\n",
    "    attrs = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', 'end')):\n",
    "        if event == 'end':\n",
    "            for attr in elem.attrib:\n",
    "                if attr not in attrs:\n",
    "                    attrs[attr] = 1\n",
    "                else:\n",
    "                    attrs[attr] += 1\n",
    "    return attrs\n",
    "\n",
    "start_time = time.time()\n",
    "attrs = count_attrs(osm_filename)\n",
    "sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in attrs.items()], reverse=True)]\n",
    "\n",
    "print 'Attributes and occurrence of alpharetta.osm:\\n'\n",
    "pprint.pprint(sorted_by_occurrence)\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys and occurrence in alpharetta.osm:\n",
      "\n",
      "\n",
      "Total number of attreibutes name found: 312\n",
      "[('building', 22983),\n",
      " ('addr:housenumber', 19004),\n",
      " ('addr:street', 18971),\n",
      " ('addr:city', 18938),\n",
      " ('highway', 17273),\n",
      " ('addr:postcode', 16568),\n",
      " ('source', 7459),\n",
      " ('name', 5508),\n",
      " ('tiger:county', 4428),\n",
      " ('tiger:cfcc', 4412),\n",
      " ('attribution', 4407),\n",
      " ('service', 4400),\n",
      " ('tiger:reviewed', 4230),\n",
      " ('tiger:name_base', 3763),\n",
      " ('tiger:name_type', 3499),\n",
      " ('Fulton:id', 3169),\n",
      " ('tiger:zip_left', 3010),\n",
      " ('tiger:zip_right', 2961),\n",
      " ('oneway', 2692),\n",
      " ('fcgis:STRUCT_USE', 1787),\n",
      " ('fcgis:YR_BUILT', 1784),\n",
      " ('fcgis:STORIES', 1784),\n",
      " ('fcgis:GFSF', 1784),\n",
      " ('fcgis:BLDG_FORM', 1784),\n",
      " ('fcgis:GEO_OID', 1782),\n",
      " ('surface', 1446),\n",
      " ('tiger:upload_uuid', 918),\n",
      " ('tiger:tlid', 918),\n",
      " ('tiger:source', 918),\n",
      " ('tiger:separated', 917),\n",
      " ('lanes', 844),\n",
      " ('LandPro08:LC', 785),\n",
      " ('LandPro08:LU', 784),\n",
      " ('LandPro08:LC_NAME', 784),\n",
      " ('LandPro08:LCLU', 784),\n",
      " ('LandPro08:DE5', 784),\n",
      " ('LandPro08:LU_NAME', 783),\n",
      " ('LandPro08:DE3', 782),\n",
      " ('amenity', 657),\n",
      " ('NHD:FCode', 617),\n",
      " ('NHD:ComID', 617),\n",
      " ('natural', 609),\n",
      " ('maxspeed', 546),\n",
      " ('landuse', 513),\n",
      " ('leisure', 491),\n",
      " ('ele', 470),\n",
      " ('created_by', 399),\n",
      " ('addr:state', 368),\n",
      " ('waterway', 358),\n",
      " ('sport', 350),\n",
      " ('tiger:name_base_1', 331),\n",
      " ('NHD:way_id', 325),\n",
      " ('NHD:FType', 325),\n",
      " ('ref', 317),\n",
      " ('NHD:RESOLUTION', 292),\n",
      " ('NHD:FTYPE', 292),\n",
      " ('NHD:FDate', 292),\n",
      " ('NHD:ReachCode', 280),\n",
      " ('power', 249),\n",
      " ('footway', 214),\n",
      " ('foot', 187),\n",
      " ('bicycle', 184),\n",
      " ('HFCS', 183),\n",
      " ('sidewalk', 181),\n",
      " ('type', 179),\n",
      " ('gnis:feature_id', 162),\n",
      " ('turn:lanes', 161),\n",
      " ('building:levels', 152),\n",
      " ('crossing', 141),\n",
      " ('gnis:created', 135),\n",
      " ('gnis:state_id', 133),\n",
      " ('gnis:county_id', 133),\n",
      " ('NHS', 132),\n",
      " ('layer', 103),\n",
      " ('tiger:name_base_2', 101),\n",
      " ('access', 101),\n",
      " ('tiger:name_direction_prefix', 93),\n",
      " ('smoothness', 91),\n",
      " ('name_1', 87),\n",
      " ('shop', 83),\n",
      " ('tiger:name_type_1', 82),\n",
      " ('bridge', 77),\n",
      " ('tiger:name_direction_suffix', 74),\n",
      " ('restriction', 73),\n",
      " ('parking', 73),\n",
      " ('tiger:zip_left_1', 72),\n",
      " ('hgv', 70),\n",
      " ('cuisine', 68),\n",
      " ('source:hgv:national_network', 64),\n",
      " ('minspeed', 64),\n",
      " ('hgv:national_network', 64),\n",
      " ('source:maxspeed', 62),\n",
      " ('website', 61),\n",
      " ('phone', 59),\n",
      " ('operator', 55),\n",
      " ('traffic_calming', 52),\n",
      " ('source:geometry', 52),\n",
      " ('official_name', 51),\n",
      " ('addr:country', 51),\n",
      " ('place', 46),\n",
      " ('religion', 43),\n",
      " ('public_transport', 40),\n",
      " ('tunnel', 39),\n",
      " ('is_in', 39),\n",
      " ('implicit', 39),\n",
      " ('opening_hours', 38),\n",
      " ('lanes:forward', 36),\n",
      " ('lanes:backward', 36),\n",
      " ('destination:ref', 36),\n",
      " ('destination', 36),\n",
      " ('traffic_signals', 35),\n",
      " ('fixme', 35),\n",
      " ('tiger:zip_left_2', 34),\n",
      " ('FIXME', 34),\n",
      " ('import_uuid', 33),\n",
      " ('gnis:id', 33),\n",
      " ('gnis:ST_num', 33),\n",
      " ('gnis:ST_alpha', 33),\n",
      " ('gnis:County_num', 33),\n",
      " ('gnis:County', 33),\n",
      " ('gnis:Class', 33),\n",
      " ('motor_vehicle', 32),\n",
      " ('tiger:zip_right_1', 31),\n",
      " ('roof:shape', 31),\n",
      " ('bus', 28),\n",
      " ('wikidata', 27),\n",
      " ('description', 27),\n",
      " ('covered', 27),\n",
      " ('barrier', 27),\n",
      " ('rcn_ref', 26),\n",
      " ('gnis:county_name', 25),\n",
      " ('junction', 23),\n",
      " ('gnis:import_uuid', 23),\n",
      " ('addr:unit', 23),\n",
      " ('turn:lanes:backward', 22),\n",
      " ('tourism', 22),\n",
      " ('gnis:reviewed', 21),\n",
      " ('cycleway:right', 21),\n",
      " ('route', 20),\n",
      " ('roof:orientation', 20),\n",
      " ('fee', 19),\n",
      " ('building:part', 19),\n",
      " ('horse', 18),\n",
      " ('building:material', 18),\n",
      " ('water', 17),\n",
      " ('segregated', 17),\n",
      " ('park_ride', 17),\n",
      " ('denomination', 17),\n",
      " ('turn:lanes:forward', 16),\n",
      " ('tiger:name_base_3', 16),\n",
      " ('wikipedia', 15),\n",
      " ('tiger:zip_left_3', 15),\n",
      " ('contact:phone', 15),\n",
      " ('voltage', 14),\n",
      " ('direction', 14),\n",
      " ('cables', 14),\n",
      " ('capacity', 13),\n",
      " ('brand', 13),\n",
      " ('tiger:zip_right_2', 12),\n",
      " ('supervised', 12),\n",
      " ('note', 12),\n",
      " ('man_made', 12),\n",
      " ('boundary', 12),\n",
      " ('traffic_sign', 11),\n",
      " ('lit', 11),\n",
      " ('is_in:state', 11),\n",
      " ('alt_name', 11),\n",
      " ('admin_level', 11),\n",
      " ('to', 10),\n",
      " ('roof:colour', 10),\n",
      " ('public_transport:version', 10),\n",
      " ('network', 10),\n",
      " ('from', 10),\n",
      " ('entrance', 10),\n",
      " ('contact:website', 10),\n",
      " ('area', 10),\n",
      " ('url', 9),\n",
      " ('office', 9),\n",
      " ('is_in:country', 9),\n",
      " ('border_type', 9),\n",
      " ('old_name', 8),\n",
      " ('population', 7),\n",
      " ('level', 7),\n",
      " ('width', 6),\n",
      " ('via', 6),\n",
      " ('maxspeed:advisory', 6),\n",
      " ('atm', 6),\n",
      " ('aeroway', 6),\n",
      " ('NHD:GNIS_Name', 6),\n",
      " ('NHD:GNIS_ID', 6),\n",
      " ('toilets:disposal', 5),\n",
      " ('tiger:zip_right_3', 5),\n",
      " ('tiger:STATEFP', 5),\n",
      " ('tiger:PLCIDFP', 5),\n",
      " ('tiger:PLACENS', 5),\n",
      " ('tiger:PLACEFP', 5),\n",
      " ('tiger:PCINECTA', 5),\n",
      " ('tiger:PCICBSA', 5),\n",
      " ('tiger:NAMELSAD', 5),\n",
      " ('tiger:NAME', 5),\n",
      " ('tiger:MTFCC', 5),\n",
      " ('tiger:LSAD', 5),\n",
      " ('tiger:FUNCSTAT', 5),\n",
      " ('tiger:CPI', 5),\n",
      " ('tiger:CLASSFP', 5),\n",
      " ('step_count', 5),\n",
      " ('is_in:state_code', 5),\n",
      " ('is_in:iso_3166_2', 5),\n",
      " ('is_in:country_code', 5),\n",
      " ('drive_through', 5),\n",
      " ('addr:suite', 5),\n",
      " ('source:population', 4),\n",
      " ('smoking', 4),\n",
      " ('short_name', 4),\n",
      " ('quantity', 4),\n",
      " ('note:lanes', 4),\n",
      " ('nist:state_fips', 4),\n",
      " ('nist:fips_code', 4),\n",
      " ('name:en', 4),\n",
      " ('motorcar', 4),\n",
      " ('cycleway', 4),\n",
      " ('wheelchair', 3),\n",
      " ('tiger:name_type_2', 3),\n",
      " ('tiger:name_direction_suffix_2', 3),\n",
      " ('takeaway', 3),\n",
      " ('ref:walmart', 3),\n",
      " ('payment:visa', 3),\n",
      " ('payment:mastercard', 3),\n",
      " ('payment:american_express', 3),\n",
      " ('note:maxspeed', 3),\n",
      " ('name_2', 3),\n",
      " ('name:ru', 3),\n",
      " ('motorcycle', 3),\n",
      " ('material', 3),\n",
      " ('internet_access', 3),\n",
      " ('information', 3),\n",
      " ('construction', 3),\n",
      " ('backrest', 3),\n",
      " ('addr:full', 3),\n",
      " ('toll', 2),\n",
      " ('tiger:zip_right_4', 2),\n",
      " ('tiger:zip_left_4', 2),\n",
      " ('symbol', 2),\n",
      " ('payment:discover_card', 2),\n",
      " ('payment:cash', 2),\n",
      " ('operator_1', 2),\n",
      " ('maxheight', 2),\n",
      " ('leaf_type', 2),\n",
      " ('leaf_cycle', 2),\n",
      " ('intermittent', 2),\n",
      " ('history', 2),\n",
      " ('historic', 2),\n",
      " ('gnis:feature_type', 2),\n",
      " ('gnis:edited', 2),\n",
      " ('fax', 2),\n",
      " ('email', 2),\n",
      " ('destination:lanes', 2),\n",
      " ('designation', 2),\n",
      " ('craft', 2),\n",
      " ('collection_times', 2),\n",
      " ('census:population', 2),\n",
      " ('building:name', 2),\n",
      " ('building:levels:aboveground', 2),\n",
      " ('addr:housename', 2),\n",
      " ('vending', 1),\n",
      " ('unsigned_ref', 1),\n",
      " ('traffic_signals:direction', 1),\n",
      " ('tower:type', 1),\n",
      " ('tower:construction', 1),\n",
      " ('tiger:name_direction_suffix_1', 1),\n",
      " ('socket:type1_combo', 1),\n",
      " ('socket:type1', 1),\n",
      " ('snowmobile', 1),\n",
      " ('ski', 1),\n",
      " ('site', 1),\n",
      " ('shelter_type', 1),\n",
      " ('route_master', 1),\n",
      " ('restriction:conditional', 1),\n",
      " ('repair', 1),\n",
      " ('rabbit', 1),\n",
      " ('pricerange', 1),\n",
      " ('payment:visa_debit', 1),\n",
      " ('payment:discover', 1),\n",
      " ('payment:cheque', 1),\n",
      " ('outdoor_seating', 1),\n",
      " ('noexit', 1),\n",
      " ('name:es', 1),\n",
      " ('mtb', 1),\n",
      " ('line', 1),\n",
      " ('leisure_1', 1),\n",
      " ('hoops', 1),\n",
      " ('highway_1', 1),\n",
      " ('height', 1),\n",
      " ('fuel:diesel', 1),\n",
      " ('faa', 1),\n",
      " ('emergency', 1),\n",
      " ('dog', 1),\n",
      " ('disused', 1),\n",
      " ('diaper', 1),\n",
      " ('destination:ref:lanes', 1),\n",
      " ('delivery', 1),\n",
      " ('cycle_network', 1),\n",
      " ('cat', 1),\n",
      " ('board_type', 1),\n",
      " ('addr:interpolation', 1),\n",
      " ('addr:inclusion', 1),\n",
      " ('abandoned:highway', 1),\n",
      " ('USGS-LULC:STATECTY', 1),\n",
      " ('USGS-LULC:LEVEL_II', 1),\n",
      " ('USGS-LULC:LEVEL_I', 1),\n",
      " ('USGS-LULC:CNTYNAME', 1),\n",
      " ('USGS-LULC:CLASS', 1)]\n",
      "\n",
      "--- 2.95700001717 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#From case study\n",
    "def count_keys(filename):\n",
    "    keys = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', 'end')):\n",
    "        if event == 'end':\n",
    "            key = elem.attrib.get('k')\n",
    "            if key:\n",
    "                if key not in keys:\n",
    "                    keys[key] = 1\n",
    "                else:\n",
    "                    keys[key] += 1\n",
    "    return keys\n",
    "\n",
    "start_time = time.time()\n",
    "keys = count_keys(osm_filename)\n",
    "sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in keys.items()], reverse=True)]\n",
    "\n",
    "print 'Keys and occurrence in alpharetta.osm:\\n'\n",
    "\n",
    "#for i in range(10):\n",
    "#    pprint.pprint(sorted_by_occurrence[i])\n",
    "\n",
    "print('\\nTotal number of attreibutes name found: %d' % len(sorted_by_occurrence))\n",
    "\n",
    "pprint.pprint(sorted_by_occurrence)\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital = re.compile(r'^([A-Z]|_)*$')\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "#double_colon = re.compile(r'^([a-zA-Z_0-9]|_)*:([a-zA-Z_0-9]|_)*:([a-zA-Z_0-9]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        \n",
    "        if capital.search(element.attrib['k']):\n",
    "            keys['capital'] += 1\n",
    "        elif lower.search(element.attrib['k']):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon'] += 1            \n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] += 1\n",
    "            print element.attrib['k']\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "            #print element.attrib['k']\n",
    "        \n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_map(filename):\n",
    "    keys = {'capital': 0, \"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key types and occurrence in alpharetta.osm:\n",
      "{'capital': 349,\n",
      " 'lower': 75328,\n",
      " 'lower_colon': 105597,\n",
      " 'other': 23563,\n",
      " 'problemchars': 0}\n",
      "\n",
      "--- 3.10800004005 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "keys = process_map(osm_filename)\n",
    "\n",
    "print 'Key types and occurrence in alpharetta.osm:'\n",
    "pprint.pprint(keys)\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postcode values and occurrence in alpharetta.osm:\n",
      "\n",
      "[('30076', 9034),\n",
      " ('30022', 3773),\n",
      " ('30075', 1877),\n",
      " ('30004', 1425),\n",
      " ('30350', 417),\n",
      " ('30009', 24),\n",
      " ('30005', 13),\n",
      " ('58502', 1),\n",
      " ('30092', 1),\n",
      " ('30041', 1),\n",
      " ('30040', 1),\n",
      " ('300009', 1)]\n",
      "12\n",
      "\n",
      "--- 3.08200001717 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def count_postcodes(filename):\n",
    "    postcodes = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', 'end')):\n",
    "        if event == 'end':\n",
    "            key = elem.attrib.get('k')\n",
    "            if key == 'addr:postcode':\n",
    "                postcode = elem.attrib.get('v')\n",
    "                if postcode not in postcodes:\n",
    "                    postcodes[postcode] = 1\n",
    "                else:\n",
    "                    postcodes[postcode] += 1\n",
    "    return postcodes\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "postcodes = count_postcodes(osm_filename)\n",
    "sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in postcodes.items()], reverse=True)]\n",
    "\n",
    "print 'Postcode values and occurrence in alpharetta.osm:\\n'\n",
    "pprint.pprint(sorted_by_occurrence)\n",
    "print len(sorted_by_occurrence)\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postcode(elem):\n",
    "    if elem.tag in ['node', 'way', 'relation']:\n",
    "        for tag in elem.iter():\n",
    "            if tag.get('k') == 'addr:postcode':\n",
    "                return True, tag.get('v')\n",
    "        return False, None\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_postcode(filename, cleaned_filename):\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    for child in ['node', 'way', 'relation']:\n",
    "        for elem in root.findall(child):\n",
    "            has_postcode, postcode_value = get_postcode(elem)\n",
    "            if has_postcode:\n",
    "                if postcode_value == '300009':\n",
    "                    for tag in elem.iter():\n",
    "                        if tag.get('k') == 'addr:postcode':\n",
    "                            tag.set('v', '30009')\n",
    "\n",
    "                elif postcode_value not in ['30004', '30005', '30009', '30022', '30040', \n",
    "                                          '30041', '30075', '30076', '30092', '30350']:\n",
    "                    root.remove(elem)\n",
    " #tag.set('v', better_name) 4 5 9 22 76   \n",
    "    return tree.write(cleaned_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 13.6129999161 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cleaned_postcode = 'data/cleaned_postcode.xml'\n",
    "clean_postcode(osm_filename, cleaned_postcode)\n",
    "\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postcode values and occurrence after cleaning:\n",
      "\n",
      "[('30076', 9034),\n",
      " ('30022', 3773),\n",
      " ('30075', 1877),\n",
      " ('30004', 1425),\n",
      " ('30350', 417),\n",
      " ('30009', 25),\n",
      " ('30005', 13),\n",
      " ('30092', 1),\n",
      " ('30041', 1),\n",
      " ('30040', 1)]\n"
     ]
    }
   ],
   "source": [
    "postcodes = count_postcodes(cleaned_postcode)\n",
    "sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in postcodes.items()], reverse=True)]\n",
    "\n",
    "print 'Postcode values and occurrence after cleaning:\\n'\n",
    "pprint.pprint(sorted_by_occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Avenue\", \"Boulevard\", \"Commons\", \"Court\", \"Drive\", \n",
    "            \"Lane\", \"Parkway\", \"Place\", \"Road\", \"Square\", \n",
    "            \"Street\", \"Trail\" ]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"ave\": \"Avenue\",\n",
    "            \"blvd\":\"Boulevard\",\n",
    "            'clse': 'Close',\n",
    "            \"ct\": \"Court\",\n",
    "            \"dr\": \"Drive\",\n",
    "            \"hwy\": \"Highway\",\n",
    "            \"ln\": \"Lane\",\n",
    "            \"lp\": \"Loop\",\n",
    "            \"pkwy\": \"Parkway\",\n",
    "            \"pl\": \"Place\",\n",
    "            'place': 'Place',\n",
    "            \"rd\": \"Road\",\n",
    "            \"sq\": \"Square\",\n",
    "            \"st\": \"Street\",\n",
    "            \"ste\": \"Suite\",\n",
    "            'steeplechase': 'Steeplechase Drive',\n",
    "            'trce': 'Trace',\n",
    "            \"trl\": \"Trail\",\n",
    "            \"w\": \"West\",\n",
    "            \"n\": \"North\",\n",
    "            \"s\": \"South\",\n",
    "            \"e\": \"East\",            \n",
    "            \"ne\": \"Northeast\",\n",
    "            \"se\": \"Southeast\",\n",
    "            \"nw\": \"Northwest\",\n",
    "            \"sw\": \"Southwest\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "    name_part = name.split(',')[0]\n",
    "    name_list = re.findall(r\"[\\w']+\", name_part)\n",
    "    end_of_street_name = len(name_list)\n",
    "    \n",
    "    if name_list[0].isdigit():\n",
    "        del name_list[0]\n",
    "    \n",
    "    if name_list[0] == 'St':\n",
    "        name_list[0] = 'Saint'\n",
    "        return ' '.join(name_list)\n",
    "    \n",
    "    for i in range(len(name_list)):\n",
    "        word = name_list[i].lower()\n",
    "        if word in mapping:\n",
    "            end_of_street_name = i\n",
    "            name_list[i] = mapping[word]\n",
    "        \n",
    "    name_list = name_list[:(end_of_street_name+1)]\n",
    "    better_name = ' '.join(name_list)\n",
    "    return better_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': set(['Morris Road, 6th Floor, Building 1']),\n",
      " '1188': set(['North Point Circle, Space 1188']),\n",
      " 'Alley': set(['Hidden Alley']),\n",
      " 'Bay': set(['Benmore Bay']),\n",
      " 'Bend': set(['Hambledon Bend']),\n",
      " 'Bluff': set(['Chimney Bluff',\n",
      "               'North Bluff',\n",
      "               'North Eagles Bluff',\n",
      "               'Tahoe Bluff']),\n",
      " 'Chase': set(['Bluffwind Chase',\n",
      "               'Brayward Chase',\n",
      "               'Foxworth Chase',\n",
      "               'Park Chase',\n",
      "               'Shadow Creek Chase',\n",
      "               'Taylor Meadow Chase']),\n",
      " 'Chute': set(['Briers Chute']),\n",
      " 'Circle': set(['Autry Landing Circle',\n",
      "                'Autry Mills Circle',\n",
      "                'Carriage Station Circle',\n",
      "                'Cedar Knoll Circle',\n",
      "                'Charleston Circle',\n",
      "                'Chattahoochee Circle',\n",
      "                'Crabapple Lake Circle',\n",
      "                'Crestview Circle',\n",
      "                'Dunwoody Creek Circle',\n",
      "                'East Creek Circle',\n",
      "                'Eves Circle',\n",
      "                'Foxbrush Circle',\n",
      "                'Foxmoor Circle',\n",
      "                'Greenmont Circle',\n",
      "                'Harvest Circle',\n",
      "                'Hembree Circle',\n",
      "                'Hembree Forest Circle',\n",
      "                'Jade Cove Circle',\n",
      "                'Jennifer Oaks Circle',\n",
      "                'Lake Forest Circle',\n",
      "                'Laurel Circle',\n",
      "                'Long Beach Circle',\n",
      "                'Lunsford Circle',\n",
      "                'Lynne Circle',\n",
      "                'Mansell Circle',\n",
      "                'Mayfield Circle',\n",
      "                'Millbrook Circle',\n",
      "                'Musette Circle',\n",
      "                'Nathan Circle',\n",
      "                'Niagara Circle',\n",
      "                'North Point Circle',\n",
      "                'North Pond Circle',\n",
      "                'Owens Oak Circle',\n",
      "                'Parnham Circle',\n",
      "                'Pindell Circle',\n",
      "                'Providence Oaks Circle',\n",
      "                'Quay Circle',\n",
      "                'Richards Circle',\n",
      "                'River Mill Circle',\n",
      "                'Roswell Commons Circle',\n",
      "                'Saddle Creek Circle',\n",
      "                'Saddle Horn Circle',\n",
      "                'Sawtooth Circle',\n",
      "                'Scotney Glen Circle',\n",
      "                'Sea Holly Circle',\n",
      "                'Softwood Circle',\n",
      "                'Southwind Circle',\n",
      "                'Sweet Apple Circle',\n",
      "                'Tiber Circle',\n",
      "                'Timbercreek Circle',\n",
      "                'Tyson Circle',\n",
      "                'Vickery Circle',\n",
      "                'Warm Springs Circle',\n",
      "                'Windfaire Circle',\n",
      "                'Zion Circle']),\n",
      " 'Close': set(['Branchwind Close',\n",
      "               'Cliffchase Close',\n",
      "               'Cupit Close',\n",
      "               'Gorham Close',\n",
      "               'Hughes Branch Close',\n",
      "               'Marshview Close',\n",
      "               'Martins Lake Close',\n",
      "               'Mistwater Close',\n",
      "               'Ridge Point Close',\n",
      "               'Saint Ignaius Close',\n",
      "               'Stoneglen Close',\n",
      "               'Summer Oaks Close',\n",
      "               'Taylor Knoll Close',\n",
      "               'Twinspur Close']),\n",
      " 'Clse': set(['Post Oak Clse']),\n",
      " 'Connection': set(['Cranberry Connection']),\n",
      " 'Copse': set(['Cullen Copse']),\n",
      " 'Cove': set(['Amethyst Cove',\n",
      "              'Canopy Cove',\n",
      "              'Forest Breeze Cove',\n",
      "              'Hunters Cove',\n",
      "              'Lochan Cove',\n",
      "              'Windlake Cove']),\n",
      " 'Creek': set(['Cranberry Creek']),\n",
      " 'Crest': set(['Argylls Crest']),\n",
      " 'Crossing': set(['East Hembree Crossing',\n",
      "                  'Old Chartwell Crossing',\n",
      "                  'Raintree Crossing',\n",
      "                  'West Hembree Crossing']),\n",
      " 'Downs': set(['Barrow Downs']),\n",
      " 'Dr': set(['Chenery Dr']),\n",
      " 'East': set(['Creekwood Crossing East',\n",
      "              'Mansell Court East',\n",
      "              'North Point Center East']),\n",
      " 'Entry': set(['Jacobean Entry', 'Landing Entry', 'Musket Entry']),\n",
      " 'Falls': set(['Watermill Falls']),\n",
      " 'Gate': set(['Gentry Gate']),\n",
      " 'Glen': set(['Willshire Glen']),\n",
      " 'Grove': set(['Guildhall Grove']),\n",
      " 'Highway': set(['Alpharetta Highway',\n",
      "                 'Atlanta Highway',\n",
      "                 'Birmingham Highway']),\n",
      " 'Hollow': set(['Hedge Row Hollow', 'Hembree Hollow']),\n",
      " 'Hwy': set(['Birmingham Hwy']),\n",
      " 'Knoll': set(['Liberty Knoll', 'Tyson Knoll']),\n",
      " 'Landing': set(['Grimes Bridge Landing',\n",
      "                 'Old Sandhurst Landing',\n",
      "                 'Paper Mill Landing']),\n",
      " 'Ln': set(['Merganser Ln']),\n",
      " 'Loop': set(['Barrington Loop']),\n",
      " 'Manor': set(['Hall Manor', 'Worthington Hills Manor']),\n",
      " 'Moor': set(['Marquess Moor']),\n",
      " 'Northeast': set(['Winding River Drive Northeast']),\n",
      " 'Overlook': set(['Arbor Creek Overlook',\n",
      "                  'Hembree Grove Overlook',\n",
      "                  'Lake Overlook']),\n",
      " 'Pass': set(['Jameson Pass', 'Lake Forest Pass', 'Old Southwick Pass']),\n",
      " 'Path': set(['Pearwood Path']),\n",
      " 'Peak': set(['Kings Peak']),\n",
      " 'Pkwy': set(['6000 North Point Pkwy']),\n",
      " 'Plaza': set(['Park Plaza']),\n",
      " 'Point': set(['Brookmill Point',\n",
      "               'Junction Point',\n",
      "               'Old Ellis Point',\n",
      "               'River Terrace Point',\n",
      "               'Starboard Point',\n",
      "               'Surrey Point']),\n",
      " 'Pointe': set(['Terrace Lake Pointe']),\n",
      " 'Ridge': set(['Stuart Ridge', 'West Lakeview Ridge']),\n",
      " 'Run': set(['Cedar Run',\n",
      "             'Misty River Run',\n",
      "             'Quail Run',\n",
      "             'Redlion Run',\n",
      "             'Squirrel Run',\n",
      "             'Tahoe Run',\n",
      "             'Trotter Run']),\n",
      " 'St': set(['Norcross St']),\n",
      " 'Station': set(['Old Sandhurst Station']),\n",
      " 'Steeplechase': set(['Steeplechase']),\n",
      " 'Terrace': set(['Clear Creek Terrace',\n",
      "                 'Clubside Terrace',\n",
      "                 'Courtyard Terrace',\n",
      "                 'Delmont Terrace',\n",
      "                 'Laurel Mill Terrace',\n",
      "                 'Leeds Garden Terrace',\n",
      "                 'Sheringham Terrace',\n",
      "                 'Springlake Terrace',\n",
      "                 'Tallwood Terrace',\n",
      "                 'Walnut Terrace',\n",
      "                 'Waterbrook Terrace',\n",
      "                 'Wentworth Terrace']),\n",
      " 'Trace': set(['Aubusson Trace',\n",
      "               'Bluffview Trace',\n",
      "               'Camber Trace',\n",
      "               'Club Walk Trace',\n",
      "               'Destiny Trace',\n",
      "               'Fall Creek Trace',\n",
      "               'Farm Grove Trace',\n",
      "               'Greenvine Trace',\n",
      "               'Gunlock Trace',\n",
      "               'High Creek Trace',\n",
      "               'Huntcliff Trace',\n",
      "               'Liberty Trace',\n",
      "               'Meadowsweet Trace',\n",
      "               'Mid Broadwell Trace',\n",
      "               'Mistwater Trace',\n",
      "               'North Hickory Trace',\n",
      "               'North Trace',\n",
      "               'Northcliff Trace',\n",
      "               'Northpointe Trace',\n",
      "               'Orchard Trace',\n",
      "               'Parkmont Trace',\n",
      "               'River Trace',\n",
      "               'Saddle Ridge Trace',\n",
      "               'Shady River Trace',\n",
      "               'Spindletree Trace',\n",
      "               'Spring Ridge Trace',\n",
      "               'Stonemist Trace',\n",
      "               'Sweetwater Trace',\n",
      "               'Truehedge Trace',\n",
      "               'Welford Trace',\n",
      "               'Wood Valley Trace']),\n",
      " 'Track': set(['Junction Track']),\n",
      " 'Trce': set(['N Hillbrooke Trce']),\n",
      " 'Turn': set(['Gable Gate Turn']),\n",
      " 'View': set(['Old Knoll View']),\n",
      " 'Vine': set(['Hope Vine']),\n",
      " 'Walk': set(['Greenmont Walk',\n",
      "              'Hambledon Walk',\n",
      "              'Heritage Walk',\n",
      "              'Itaska Walk',\n",
      "              'Kenley Walk',\n",
      "              'Shoreline Walk',\n",
      "              'Sydney Walk']),\n",
      " 'Way': set(['Almont Way',\n",
      "             'Annie Cook Way',\n",
      "             'Arbor Creek Way',\n",
      "             'Autry Landing Way',\n",
      "             'Bainbridge Way',\n",
      "             'Barrington Way',\n",
      "             'Baywood Way',\n",
      "             'Blessing Way',\n",
      "             'Branch Valley Way',\n",
      "             'Brumbelow Crossing Way',\n",
      "             'Burnett Way',\n",
      "             'Camellia Way',\n",
      "             'Canberra Way',\n",
      "             'Chads Ford Way',\n",
      "             'Chason Wood Way',\n",
      "             'Cobblestone Way',\n",
      "             'Combees Way',\n",
      "             'Compton Way',\n",
      "             'Crab Orchard Way',\n",
      "             'Crabapple Parc Way',\n",
      "             'Cranberry Way',\n",
      "             'Creekmont Way',\n",
      "             'Crique Way',\n",
      "             'Danbridge Way',\n",
      "             'Delft Way',\n",
      "             'Dominion Way',\n",
      "             'English Rose Way',\n",
      "             'Geddy Way',\n",
      "             'Glen River Way',\n",
      "             'Great Oaks Way',\n",
      "             'Green Elm Way',\n",
      "             'Greening Way',\n",
      "             'Grove Way',\n",
      "             'Hollyridge Way',\n",
      "             'Holyrood Way',\n",
      "             'Houze Way',\n",
      "             'Innovation Way',\n",
      "             'Ivy Mill Way',\n",
      "             'Kings Arms Way',\n",
      "             'Kingsworth Way',\n",
      "             'Knightsbridge Way',\n",
      "             'Kristian Way',\n",
      "             'La View Way',\n",
      "             'Lake Forest Way',\n",
      "             'Lakeland Way',\n",
      "             'Laketop Way',\n",
      "             'Laurel Mill Way',\n",
      "             'Laurel Way',\n",
      "             'Leasingworth Way',\n",
      "             'Loch Tay Way',\n",
      "             'Matterhorn Way',\n",
      "             'May Glen Way',\n",
      "             'McIntosh Way',\n",
      "             'Meuse Way',\n",
      "             'Mount Mitchell Way',\n",
      "             'Mount Ranier Way',\n",
      "             'Nautica Way',\n",
      "             'North Pond Way',\n",
      "             'Northfield Way',\n",
      "             'Northwick Pass Way',\n",
      "             'Norwick Way',\n",
      "             'Oak Alley Way',\n",
      "             'Old Ferry Way',\n",
      "             'Old Pewter Way',\n",
      "             'Penhurst Way',\n",
      "             'Pine Brook Way',\n",
      "             'Providence Place Way',\n",
      "             'Raintree Way',\n",
      "             'Redcoat Way',\n",
      "             'Renaissance Way',\n",
      "             'Ridge Way',\n",
      "             'Riversong Way',\n",
      "             'Rock Mill Way',\n",
      "             'Roswell Commons Way',\n",
      "             'Scarborough Way',\n",
      "             'Serendipity Way',\n",
      "             'Shade Tree Way',\n",
      "             'Sherman Oaks Way',\n",
      "             'South Gable Way',\n",
      "             'Streamview Way',\n",
      "             'Sweetwood Way',\n",
      "             'Taberwood Way',\n",
      "             'Terramont Way',\n",
      "             'Tigris Way',\n",
      "             'Trevelyan Way',\n",
      "             'Venue Way',\n",
      "             'Vickery Way',\n",
      "             'Watergate Way',\n",
      "             'Waterstone Way',\n",
      "             'Weatherstone Way',\n",
      "             'Wedgewood Way',\n",
      "             'Westbourne Way',\n",
      "             'Wheeler Peak Way',\n",
      "             'Whitehall Way',\n",
      "             'Whitesmith Way',\n",
      "             'Willow Way',\n",
      "             'Windalier Way',\n",
      "             'Winesap Way',\n",
      "             'Wood Work Way']),\n",
      " 'West': set(['Creekwood Crossing West']),\n",
      " 'Wood': set(['Stradford Wood']),\n",
      " 'Woods': set(['Merriweather Woods']),\n",
      " 'place': set(['Harris Commons place'])}\n",
      "61\n",
      "\n",
      "--- 3.17699980736 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "street_types = audit(cleaned_postcode)\n",
    "pprint.pprint(dict(street_types))\n",
    "print len(street_types)\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merganser Ln => Merganser Lane\n",
      "Providence Place Way => Providence Place\n",
      "Morris Road, 6th Floor, Building 1 => Morris Road\n",
      "Birmingham Hwy => Birmingham Highway\n",
      "Chenery Dr => Chenery Drive\n",
      "Steeplechase => Steeplechase Drive\n",
      "6000 North Point Pkwy => North Point Parkway\n",
      "Norcross St => Norcross Street\n",
      "North Point Circle, Space 1188 => North Point Circle\n",
      "Harris Commons place => Harris Commons Place\n",
      "N Hillbrooke Trce => North Hillbrooke Trace\n",
      "Post Oak Clse => Post Oak Close\n",
      "\n",
      "--- 0.00399994850159 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for st_type, ways in street_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        if name != better_name:\n",
    "            print name, \"=>\", better_name\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 13.3680000305 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def clean_street_name(filename, cleaned_filename):\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for tag in root.findall('*/tag'):\n",
    "        if is_street_name(tag):\n",
    "            name = tag.get('v')\n",
    "            better_name = update_name(name, mapping)\n",
    "            tag.set('v', better_name)\n",
    "\n",
    "    return tree.write(cleaned_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 13.3459999561 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cleaned_street_name = 'data/cleaned_street_name.xml'\n",
    "clean_street_name(cleaned_postcode, cleaned_street_name)\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.26600003242 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "street_types = audit(cleaned_street_name)\n",
    "\n",
    "for st_type, ways in street_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        if name != better_name:\n",
    "            print name, \"=>\", better_name\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of phone numbers: 116\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count_number = 0\n",
    "for _, element in ET.iterparse(cleaned_street_name, ('start', 'end')):\n",
    "    if  element.tag == \"tag\":\n",
    "        if element.attrib['k'] == 'phone':\n",
    "            count_number += 1\n",
    "\n",
    "print 'Total count of phone numbers:', count_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_only = re.compile(r'\\d+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_type(element, number_types):\n",
    "    if element.tag == \"tag\":\n",
    "        if element.attrib['k'] == 'phone':\n",
    "            if digit_only.match(element.attrib['v']):\n",
    "                number_types['digit_only'] += 1\n",
    "            else:\n",
    "                number_types['other'] += 1\n",
    "                print element.attrib['v']\n",
    "        \n",
    "    return number_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_map(filename):\n",
    "    number_types = {\"digit_only\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename, ('start', 'end')):\n",
    "        number_types = number_type(element, number_types)\n",
    "\n",
    "    return number_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1 770 993 9031\n",
      "+1 770 993 9031\n",
      "+1-404-754-9290\n",
      "+1-404-754-9290\n",
      "+1-770-346-9119\n",
      "+1-770-346-9119\n",
      "(770) 284-3101\n",
      "(770) 284-3101\n",
      "+1 (678) 319-0018\n",
      "+1 (678) 319-0018\n",
      "+1 (770) 410-1122\n",
      "+1 (770) 410-1122\n",
      "(770) 642-0395\n",
      "(770) 642-0395\n",
      "(770) 992-1617\n",
      "(770) 992-1617\n",
      "(770) 552-1390\n",
      "(770) 552-1390\n",
      "+1 404 452 9263\n",
      "+1 404 452 9263\n",
      "(888) 660-5890\n",
      "(888) 660-5890\n",
      "+1 770 3469880\n",
      "+1 770 3469880\n",
      "+1 770 5968985\n",
      "+1 770 5968985\n",
      "+1 (770) 569-7298\n",
      "+1 (770) 569-7298\n",
      "(770) 817-4656\n",
      "(770) 817-4656\n",
      "+1-470-282-5400\n",
      "+1-470-282-5400\n",
      "+1-770-360-8014\n",
      "+1-770-360-8014\n",
      "+1-678-777-6385\n",
      "+1-678-777-6385\n",
      "+1-404-587-4573\n",
      "+1-404-587-4573\n",
      "+1 (678) 393-8333\n",
      "+1 (678) 393-8333\n",
      "+1-770-587-4595\n",
      "+1-770-587-4595\n",
      "+1-770-475-4101\n",
      "+1-770-475-4101\n",
      "(770) 691-0637\n",
      "(770) 691-0637\n",
      "(404) 369-1302\n",
      "(404) 369-1302\n",
      "+1 770 740 7050\n",
      "+1 770 740 7050\n",
      "+1-770-772-9033\n",
      "+1-770-772-9033\n",
      "+1 (678) 280-0550\n",
      "+1 (678) 280-0550\n",
      "(678) 393-0101\n",
      "(678) 393-0101\n",
      "+1 770 3607766\n",
      "+1 770 3607766\n",
      "+1 (678) 461-7900\n",
      "+1 (678) 461-7900\n",
      "+1-770-993-0533\n",
      "+1-770-993-0533\n",
      "(770) 993-0299\n",
      "(770) 993-0299\n",
      "+1 (770) 992-5688\n",
      "+1 (770) 992-5688\n",
      "+1 (678) 352-9937\n",
      "+1 (678) 352-9937\n",
      "+1 (770) 552-5599\n",
      "+1 (770) 552-5599\n",
      "+1 (770) 992-1407\n",
      "+1 (770) 992-1407\n",
      "+1 (770) 993-9804\n",
      "+1 (770) 993-9804\n",
      "+1 (770) 993-8587\n",
      "+1 (770) 993-8587\n",
      "+1 (404) 875-5331\n",
      "+1 (404) 875-5331\n",
      "+1 (770) 643-1471\n",
      "+1 (770) 643-1471\n",
      "(770) 569-9660\n",
      "(770) 569-9660\n",
      "+1 (678) 352-9020\n",
      "+1 (678) 352-9020\n",
      "+1 (770) 998-7615\n",
      "+1 (770) 998-7615\n",
      "(770) 663-8833\n",
      "(770) 663-8833\n",
      "+1 770 751 2500\n",
      "+1 770 751 2500\n",
      "+1 770 664 8644\n",
      "+1 770 664 8644\n",
      "+1 (770) 753-2671\n",
      "+1 (770) 753-2671\n",
      "{'digit_only': 22, 'other': 94}\n",
      "\n",
      "--- 3.31999993324 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pprint.pprint(process_map(cleaned_street_name))\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_phone_number(filename, cleaned_filename):\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for tag in root.findall('*/tag'):\n",
    "        if tag.attrib['k'] == 'phone':\n",
    "            phone_number = tag.get('v')\n",
    "            if not digit_only.match(phone_number):\n",
    "                update_phone_number = re.sub(r'[\\D|\\s]+', '', phone_number)[-10: ]\n",
    "                tag.set('v', update_phone_number)\n",
    "\n",
    "    return tree.write(cleaned_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'digit_only': 116, 'other': 0}\n",
      "\n",
      "--- 16.8329999447 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cleaned_phone_number = 'data/cleaned_phone_number.xml'\n",
    "clean_phone_number(cleaned_street_name, cleaned_phone_number)\n",
    "\n",
    "pprint.pprint(process_map(cleaned_phone_number))\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "DATADIR = 'Prepared CSV\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES_PATH = os.path.join(DATADIR, \"nodes.csv\")\n",
    "NODE_TAGS_PATH = os.path.join(DATADIR, \"nodes_tags.csv\")\n",
    "WAYS_PATH = os.path.join(DATADIR, \"ways.csv\")\n",
    "WAY_NODES_PATH = os.path.join(DATADIR, \"ways_nodes.csv\")\n",
    "WAY_TAGS_PATH = os.path.join(DATADIR, \"ways_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  \n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in NODE_FIELDS:\n",
    "                node_attribs[attrib] = element.attrib[attrib]\n",
    "        \n",
    "        for child in element:\n",
    "            node_tag = {}\n",
    "            if LOWER_COLON.match(child.attrib['k']):\n",
    "                node_tag['type'] = child.attrib['k'].split(':',1)[0]\n",
    "                node_tag['key'] = child.attrib['k'].split(':',1)[1]\n",
    "                node_tag['id'] = element.attrib['id']\n",
    "                node_tag['value'] = child.attrib['v']\n",
    "                tags.append(node_tag)\n",
    "            elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                continue\n",
    "            else:\n",
    "                node_tag['type'] = 'regular'\n",
    "                node_tag['key'] = child.attrib['k']\n",
    "                node_tag['id'] = element.attrib['id']\n",
    "                node_tag['value'] = child.attrib['v']\n",
    "                tags.append(node_tag)\n",
    "        \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "        \n",
    "    elif element.tag == 'way':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in WAY_FIELDS:\n",
    "                way_attribs[attrib] = element.attrib[attrib]\n",
    "        \n",
    "        position = 0\n",
    "        for child in element:\n",
    "            way_tag = {}\n",
    "            way_node = {}\n",
    "            \n",
    "            if child.tag == 'tag':\n",
    "                if LOWER_COLON.match(child.attrib['k']):\n",
    "                    way_tag['type'] = child.attrib['k'].split(':',1)[0]\n",
    "                    way_tag['key'] = child.attrib['k'].split(':',1)[1]\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = child.attrib['v']\n",
    "                    tags.append(way_tag)\n",
    "                elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                    continue\n",
    "                else:\n",
    "                    way_tag['type'] = 'regular'\n",
    "                    way_tag['key'] = child.attrib['k']\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = child.attrib['v']\n",
    "                    tags.append(way_tag)\n",
    "                    \n",
    "            elif child.tag == 'nd':\n",
    "                way_node['id'] = element.attrib['id']\n",
    "                way_node['node_id'] = child.attrib['ref']\n",
    "                way_node['position'] = position\n",
    "                position += 1\n",
    "                way_nodes.append(way_node)\n",
    "        \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    " #codecs.\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 803.332999945 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(cleaned_phone_number, validate=True)\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size of nodes.csv: 34.23 MB\n",
      "File size of nodes_tags.csv: 1.07 MB\n",
      "File size of ways.csv: 2.93 MB\n",
      "File size of ways_nodes.csv: 10.27 MB\n",
      "File size of ways_tags.csv: 6.40 MB\n",
      "\n",
      "--- 0.000999927520752 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#NODES_PATH = os.path.join(DATADIR, \"nodes.csv\")\n",
    "#NODE_TAGS_PATH = os.path.join(DATADIR, \"nodes_tags.csv\")\n",
    "#WAYS_PATH = os.path.join(DATADIR, \"ways.csv\")\n",
    "#WAY_NODES_PATH = os.path.join(DATADIR, \"ways_nodes.csv\")\n",
    "#WAY_TAGS_PATH = os.path.join(DATADIR, \"ways_tags.csv\")\n",
    "#os.path.getsize(local_filename)\n",
    "start_time = time.time()\n",
    "print('File size of nodes.csv: %.2f MB' % (float(os.path.getsize(NODES_PATH))/1000000))\n",
    "print('File size of nodes_tags.csv: %.2f MB' % (float(os.path.getsize(NODE_TAGS_PATH))/1000000))\n",
    "print('File size of ways.csv: %.2f MB' % (float(os.path.getsize(WAYS_PATH))/1000000))\n",
    "print('File size of ways_nodes.csv: %.2f MB' % (float(os.path.getsize(WAY_NODES_PATH))/1000000))\n",
    "print('File size of ways_tags.csv: %.2f MB' % (float(os.path.getsize(WAY_TAGS_PATH))/1000000))\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"OSM_alpharetta.db\")\n",
    "conn.text_factory = str\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1.85599994659 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# create nodes table\n",
    "start_time = time.time()\n",
    "\n",
    "cur.execute(\"Drop TABLE nodes;\")\n",
    "cur.execute(\"CREATE TABLE nodes (id, lat, lon, user, uid, version, changeset, timestamp);\")\n",
    "with open(NODES_PATH, 'rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['lat'], i['lon'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) \\\n",
    "             for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes (id, lat, lon, user, uid, version, changeset, timestamp) \\\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 0.15299987793 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#create nodes_tags table\n",
    "start_time = time.time()\n",
    "\n",
    "cur.execute(\"Drop TABLE nodes_tags;\")\n",
    "cur.execute(\"CREATE TABLE nodes_tags (id, key, value, type);\")\n",
    "with open(NODE_TAGS_PATH, 'rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes_tags (id, key, value, type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 0.245000123978 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Create ways table\n",
    "start_time = time.time()\n",
    "\n",
    "cur.execute(\"Drop TABLE ways;\")\n",
    "cur.execute(\"CREATE TABLE ways (id, user, uid, version, changeset, timestamp);\")\n",
    "with open(WAYS_PATH, 'rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways (id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1.35100007057 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Create ways_nodes table\n",
    "start_time = time.time()\n",
    "\n",
    "cur.execute(\"Drop TABLE ways_nodes;\")\n",
    "cur.execute(\"CREATE TABLE ways_nodes (id, node_id, position);\")\n",
    "with open(WAY_NODES_PATH, 'rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_nodes (id, node_id, position) VALUES (?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 0.650000095367 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Create ways_tags table\n",
    "start_time = time.time()\n",
    "\n",
    "cur.execute(\"CREATE TABLE ways_tags (id, key, value, type);\")\n",
    "with open(WAY_TAGS_PATH, 'rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_tags (id, key, value, type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size of OSM_alpharetta.db: 62.68 MB\n",
      "\n",
      "--- 0.0 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print('File size of OSM_alpharetta.db: %.2f MB' % (float(os.path.getsize('OSM_alpharetta.db'))/1000000))\n",
    "\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_nodes():\n",
    "    result = cur.execute('SELECT COUNT(*) FROM nodes')\n",
    "    return result.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 360142\n",
      "\n",
      "--- 0.0569999217987 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Number of nodes: %d\" % number_of_nodes())\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_ways():\n",
    "    result = cur.execute('SELECT COUNT(*) FROM ways')\n",
    "    return result.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ways: 40794\n",
      "\n",
      "--- 0.00500011444092 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Number of ways: %d\" % number_of_ways())\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_unique_users():\n",
    "    result = cur.execute(\n",
    "        'SELECT COUNT(DISTINCT(all_rec.uid)) \\\n",
    "         FROM (SELECT uid FROM nodes \\\n",
    "               UNION ALL \\\n",
    "               SELECT uid FROM ways) all_rec')\n",
    "    return result.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 317\n",
      "\n",
      "--- 0.148999929428 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Number of unique users: %d\" % number_of_unique_users())\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_contributing_users():\n",
    "    users = []\n",
    "    for row in cur.execute(\n",
    "        'SELECT all_rec.user, COUNT(*) as num \\\n",
    "         FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) all_rec \\\n",
    "         GROUP BY all_rec.user \\\n",
    "         ORDER BY num DESC \\\n",
    "         LIMIT 10'):\n",
    "        users.append(row)\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top contributing users: \n",
      "('Saikrishna_FultonCountyImport', 201863)\n",
      "('Liber', 38321)\n",
      "('woodpeck_fixbot', 37322)\n",
      "('demory', 12372)\n",
      "('Jack the Ripper', 10202)\n",
      "('afonit', 8751)\n",
      "('TeresaPeteti', 8038)\n",
      "('greenv505', 7608)\n",
      "('mackerski', 5916)\n",
      "('ranjithjoy', 4974)\n",
      "\n",
      "--- 0.208999872208 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "top_users = top_contributing_users()\n",
    "print \"Top contributing users: \"\n",
    "for i in range(len(top_users)):\n",
    "    print top_users[i]\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_users_contributing_once():\n",
    "    result = cur.execute(\n",
    "        'SELECT COUNT(*) \\\n",
    "         FROM (SELECT all_rec.user, COUNT(*) as num \\\n",
    "               FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) all_rec \\\n",
    "               GROUP BY all_rec.user \\\n",
    "               HAVING num=1) u')\n",
    "    return result.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users contributing once: 55\n",
      "\n",
      "--- 0.214999914169 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Number of users contributing once: %d\" % number_of_users_contributing_once())\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_ammenities():\n",
    "    result = []\n",
    "    for row in cur.execute('SELECT value, COUNT(*) num \\\n",
    "            FROM nodes_tags \\\n",
    "            WHERE key=\"amenity\" \\\n",
    "            GROUP BY value \\\n",
    "            ORDER BY num DESC \\\n",
    "            LIMIT 10'):\n",
    "        result.append(row)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top contributing users: \n",
      "('school', 47)\n",
      "('restaurant', 41)\n",
      "('place_of_worship', 31)\n",
      "('fast_food', 15)\n",
      "('grave_yard', 14)\n",
      "('fire_station', 11)\n",
      "('bench', 10)\n",
      "('fuel', 10)\n",
      "('cafe', 8)\n",
      "('bank', 7)\n",
      "\n",
      "--- 0.00299978256226 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "top_ammenities = common_ammenities()\n",
    "print \"Top contributing users: \"\n",
    "for i in range(len(top_ammenities)):\n",
    "    print top_ammenities[i]\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def religion():\n",
    "    result = []\n",
    "    for row in cur.execute('SELECT value, count(*) num FROM nodes_tags \\\n",
    "                WHERE key = \"religion\" \\\n",
    "                GROUP BY value \\\n",
    "                ORDER BY num'):\n",
    "        result.append(row)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Religion in the area: \n",
      "('christian', 31)\n",
      "\n",
      "--- 0.0019998550415 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "religion = religion()\n",
    "print \"Religion in the area: \"\n",
    "for i in range(len(biggest_religion)):\n",
    "    print biggest_religion[i]\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_cuisines():\n",
    "    result = []\n",
    "    for row in cur.execute('SELECT value, COUNT(*) as num \\\n",
    "                FROM nodes_tags \\\n",
    "                WHERE key=\"cuisine\" \\\n",
    "                GROUP BY value \\\n",
    "                ORDER BY num DESC \\\n",
    "                LIMIT 3'):\n",
    "        result.append(row)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular cuisines in the area: \n",
      "('mexican', 6)\n",
      "('burger', 5)\n",
      "('chicken', 3)\n",
      "\n",
      "--- 0.00300002098083 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "popular_cuisines = popular_cuisines()\n",
    "print \"Popular cuisines in the area: \"\n",
    "for i in range(len(popular_cuisines)):\n",
    "    print popular_cuisines[i]\n",
    "print('\\n--- %s seconds ---' % (time.time() - start_time))\n",
    "#problem occurs when american & American"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for row in cur.execute('SELECT * FROM nodes_tags \\\n",
    "            WHERE value = \"coffee\"'):\n",
    "    result.append(row)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Starbucks', 2)]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some problem here\n",
    "result = []\n",
    "for row in cur.execute('Select n.value, count(*) \\\n",
    "            from nodes_tags n, (SELECT id FROM nodes_tags \\\n",
    "                                WHERE value = \"coffee_shop\") i\\\n",
    "            WHERE n.id = i.id \\\n",
    "              AND n.key = \"name\" \\\n",
    "            GROUP BY n.value'):\n",
    "    result.append(row)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Windward Plaza',),\n",
       " ('Newgate Court',),\n",
       " ('Bellingrath Boulevard',),\n",
       " ('Darien Park Drive',),\n",
       " ('Crabapple Lake Court',),\n",
       " ('Roxburgh Drive',),\n",
       " ('Dover Avenue',),\n",
       " ('Jenkins Court',),\n",
       " ('Dodds Grove Lane',)]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the address of all Wendy's in the area\n",
    "result = []\n",
    "for row in cur.execute('Select w2.value from nodes_tags n1, nodes_tags n2, ways_tags w1, ways_tags w2 \\\n",
    "                        Where n1.value = \"McDonald\\'s\" \\\n",
    "                          And n1.id = n2.id \\\n",
    "                          And n2.key = \"housenumber\" \\\n",
    "                          And n2.value = w1.value \\\n",
    "                          And w1.id = w2.id \\\n",
    "                          And w2.key = \"street\"'):\n",
    "    result.append(row)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2714938157',),\n",
       " ('2810148148',),\n",
       " ('4285520360',),\n",
       " ('4524912377',),\n",
       " ('5369193298',)]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for row in cur.execute('SELECT id FROM nodes_tags WHERE value = \"Starbucks\"'):\n",
    "    result.append(row)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2714938157', 'city', 'Roswell', 'addr'),\n",
       " ('2714938157', 'housenumber', '10800', 'addr'),\n",
       " ('2714938157', 'postcode', '30076', 'addr'),\n",
       " ('2714938157', 'street', 'Alpharetta Highway', 'addr'),\n",
       " ('2714938157', 'amenity', 'cafe', 'regular'),\n",
       " ('2714938157', 'cuisine', 'coffee_shop', 'regular'),\n",
       " ('2714938157', 'internet_access', 'wlan', 'regular'),\n",
       " ('2714938157', 'name', 'Starbucks', 'regular'),\n",
       " ('2714938157', 'phone', '7705521390', 'regular'),\n",
       " ('2714938157', 'website', 'http://www.starbucks.com/', 'regular')]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for row in cur.execute('Select * FROM nodes_tags \\\n",
    "            WHERE id = \"2714938157\" '):\n",
    "    result.append(row)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4141785063', 'amenity', 'fast_food', 'regular'),\n",
       " ('4141785063', 'name', 'Burger King', 'regular')]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for row in cur.execute('Select * FROM nodes_tags \\\n",
    "            WHERE id = \"4141785063\"'):\n",
    "    result.append(row)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for row in cur.execute('Select w2.value \\\n",
    "                        from nodes n, nodes_tags n1, nodes_tags n2, \\\n",
    "                             ways w, ways_tags w1, ways_tags w2 \\\n",
    "                        Where n1.value = \"McDonald\\'s\" \\\n",
    "                          And n1.id = n2.id \\\n",
    "                          And n1.id = n.id \\\n",
    "                          And n.uid = w.uid \\\n",
    "                          And n2.key = \"housenumber\" \\\n",
    "                          And n2.value = w1.value \\\n",
    "                          And w1.id = w2.id \\\n",
    "                          And w.id = w1.id \\\n",
    "                          And w2.key = \"street\"'):\n",
    "    result.append(row)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2013',), ('2009',), ('2009',)]"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for row in cur.execute('Select strftime(\"%Y\",timestamp) year FROM nodes limit 3'):\n",
    "    result.append(row)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2018', 29934),\n",
       " ('2017', 25556),\n",
       " ('2016', 56028),\n",
       " ('2015', 159539),\n",
       " ('2014', 17698),\n",
       " ('2013', 12013),\n",
       " ('2012', 4965),\n",
       " ('2011', 637),\n",
       " ('2010', 1710),\n",
       " ('2009', 91390),\n",
       " ('2008', 591),\n",
       " ('2007', 875)]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for row in cur.execute('Select i.year, count(*) num \\\n",
    "                        From (Select strftime(\"%Y\",timestamp) year FROM nodes \\\n",
    "                              Union ALL\\\n",
    "                              Select strftime(\"%Y\",timestamp) year FROM ways) i\\\n",
    "                        Group by year \\\n",
    "                        Order by year desc'):\n",
    "    result.append(row)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Roxburgh Drive', 155),\n",
       " ('Arborwoods Drive', 108),\n",
       " ('Martin Road', 91),\n",
       " ('Nesbit Lakes Drive', 89),\n",
       " ('Six Branches Drive', 79)]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for row in cur.execute('Select value, count(*) num FROM ways_tags \\\n",
    "                        where key =\"street\" group by value order by num desc limit 5'):\n",
    "    result.append(row)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
